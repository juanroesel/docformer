{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DocFormer for MLM",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uakarsh/docformer/blob/master/examples/DocFormer_for_MLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the environment CUDA Enabled (so that, it would be easy to process everything)"
      ],
      "metadata": {
        "id": "_6c6QiIFYTrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. About the Notebook:\n",
        "\n",
        "This notebook, demonstrates using DocFormer for the purpose of Masked language Modeling (without pre-trained weights)"
      ],
      "metadata": {
        "id": "uPPLpSLiY_5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Installing the dependencies (might take some time)\n",
        "\n",
        "%%capture\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install transformers\n",
        "!pip install pytorch-lightning\n",
        "!pip install einops\n",
        "!pip install accelerate\n",
        "!pip install tqdm\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "tfvrvE1aYWD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install 'Pillow==7.1.2'"
      ],
      "metadata": {
        "id": "n0-It2scnwBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cloning the repository\n",
        "\n",
        "%%capture\n",
        "!git clone https://github.com/shabie/docformer.git"
      ],
      "metadata": {
        "id": "Zacpx5nNDmH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing the libraries\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image,ImageDraw\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from einops import rearrange\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "## Adding the path of docformer to system path\n",
        "import sys\n",
        "sys.path.append('/content/docformer/src/docformer/')\n",
        "\n",
        "\n",
        "\n",
        "## Importing the functions from the DocFormer Repo\n",
        "from dataset import create_features\n",
        "from modeling import DocFormerEncoder,ResNetFeatureExtractor,DocFormerEmbeddings,LanguageFeatureExtractor\n",
        "from transformers import BertTokenizerFast"
      ],
      "metadata": {
        "id": "jyqD3G3fZWxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting some hyperparameters\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = {\n",
        "  \"coordinate_size\": 96,              ## (768/8), 8 for each of the 8 coordinates of x, y\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 768,\n",
        "  \"image_feature_pool_shape\": [7, 7, 256],\n",
        "  \"intermediate_ff_size_factor\": 4,\n",
        "  \"max_2d_position_embeddings\": 1024,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"max_relative_positions\": 8,\n",
        "  \"num_attention_heads\": 12,\n",
        "  \"num_hidden_layers\": 12,\n",
        "  \"pad_token_id\": 0,\n",
        "  \"shape_size\": 96,\n",
        "  \"vocab_size\": 30522,\n",
        "  \"layer_norm_eps\": 1e-12,\n",
        "}"
      ],
      "metadata": {
        "id": "TI127c5GZFMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Making the dataset"
      ],
      "metadata": {
        "id": "I_DfRAObbBdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentDataset(Dataset):\n",
        "    def __init__(self,entries,tokenizer,labels = None, use_mlm = False):\n",
        "\n",
        "        self.use_mlm = use_mlm\n",
        "        self.entries = entries\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.entries)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        ''' \n",
        "        Returns only four required inputs, \n",
        "        * resized_scaled_img\n",
        "        * input_ids\n",
        "        * x_features\n",
        "        * y_features\n",
        "\n",
        "        If labels are not None, then labels also\n",
        "        '''\n",
        "        encoding = create_features(self.entries[index],self.tokenizer, apply_mask_for_mlm=self.use_mlm)\n",
        "\n",
        "        if self.labels==None:\n",
        "\n",
        "          if self.use_mlm:\n",
        "            return encoding['resized_scaled_img'],encoding['input_ids'],encoding['x_features'],encoding['y_features'], encoding['mlm_labels']\n",
        "\n",
        "          else:\n",
        "            return encoding['resized_scaled_img'],encoding['input_ids'],encoding['x_features'],encoding['y_features']\n",
        "\n",
        "        return encoding['resized_scaled_img'],encoding['input_ids'],encoding['x_features'],encoding['y_features'], self.labels[index]"
      ],
      "metadata": {
        "id": "tz8nc5OIabSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "lGJp7IxPavPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Downloading the RVL-CDIP dataset, it contains few images for the purpose of MLM (from invoice classes of RVL-CDIP dataset)"
      ],
      "metadata": {
        "id": "ZLfyv0EXbdu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/uakarsh/sample_rvl_cdip_dataset.git"
      ],
      "metadata": {
        "id": "7eVfpEJ7ENNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/sample_rvl_cdip_dataset/RVL-CDIP Invoice Class Dataset'\n",
        "fp = pd.DataFrame({'image_id':[os.path.join(base_path,i) for i in os.listdir(base_path)]})"
      ],
      "metadata": {
        "id": "JdzWnTcJgU0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = DocumentDataset(fp['image_id'].values.tolist(),tokenizer = tokenizer, use_mlm = True)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_data_loader = DataLoader(train_ds,\n",
        "                                batch_size=2,\n",
        "                                shuffle=True,\n",
        "                                num_workers=0,\n",
        "                                collate_fn=collate_fn\n",
        "                                )"
      ],
      "metadata": {
        "id": "ekjB0TzmhzYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Making the model and doing the propagation"
      ],
      "metadata": {
        "id": "ATNE0xcAEmna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DocFormerForMLM(nn.Module):\n",
        "  \n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet = ResNetFeatureExtractor()\n",
        "        self.embeddings = DocFormerEmbeddings(config)\n",
        "        self.lang_emb = LanguageFeatureExtractor()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config['hidden_dropout_prob'])\n",
        "        self.linear_layer = nn.Linear(in_features = config['hidden_size'], out_features = config['vocab_size'])\n",
        "        self.encoder = DocFormerEncoder(config)\n",
        "\n",
        "    def forward(self, x_feat, y_feat, img, token):\n",
        "        v_bar_s, t_bar_s = self.embeddings(x_feat,y_feat)\n",
        "        v_bar = self.resnet(img)\n",
        "        t_bar = self.lang_emb(token)\n",
        "        out = self.encoder(t_bar,v_bar,t_bar_s,v_bar_s)\n",
        "        out = self.linear_layer(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "KFHueHSytLGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DocFormerForMLM(config).to(device)"
      ],
      "metadata": {
        "id": "Z4NLKC8CtvQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Using a single batch for the forward propagation\n",
        "features = next(iter(train_data_loader))\n",
        "final_data = []\n",
        "\n",
        "for i in range(len(features)):\n",
        "  final_data.append(torch.stack(features[i]))\n",
        "  \n",
        "del features\n",
        "img,token,x_feat,y_feat, labels = final_data"
      ],
      "metadata": {
        "id": "XxISODkZh-CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transferring it to device\n",
        "\n",
        "img = img.to(device)\n",
        "token = token.to(device)\n",
        "x_feat = x_feat.to(device)\n",
        "y_feat = y_feat.to(device)\n",
        "labels = labels.to(device)"
      ],
      "metadata": {
        "id": "GJKkjbL9iE1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Forward Propagation\n",
        "\n",
        "out = model(x_feat, y_feat, img, token)"
      ],
      "metadata": {
        "id": "NNqAzsvEuHnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Initializing, the loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr= 5e-5)\n",
        "\n",
        "\n",
        "## Calculating the loss and back propagating\n",
        "optimizer.zero_grad()\n",
        "loss = criterion(out.transpose(1,2), labels.long())\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "JoOMLzVkvARi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Lc7u8BgEgZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}